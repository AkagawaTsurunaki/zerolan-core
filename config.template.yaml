# Modify your config for models you want to use.

ASR:
  id: "iic/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1" # The model you want to use
  host: "0.0.0.0" # Host of the API service you want to start
  port: 11001 # Port of the API service you want to start  
  config:
    iic/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1:
      model_path: "iic/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1" # Directory of the model
      chunk_size: [0, 10, 5]  # [0, 10, 5] 600ms, [0, 8, 4] 480ms
      encoder_chunk_look_back: 4  # Number of chunks to lookback for encoder self-attention
      decoder_chunk_look_back: 1  # Number of encoder chunks to lookback for decoder cross-attention
      version: "v2.0.4" # Paraformer version
      chunk_stride: 9600  # chunk_size[1] * 960

LLM:
  id: "THUDM/chatglm3-6b" # The model you want to use
  host: "0.0.0.0" # Host of the API service you want to start
  port: 11002 # Port of the API service you want to start
  config:
    THUDM/glm-4-9b-chat-hf:
      model_path: "THUDM/glm-4-9b-chat-hf"
      device: "cuda"
      max_length: 5000
    THUDM/chatglm3-6b:
      model_path: "THUDM/chatglm3-6b" # Directory of the model
      quantize: null  # null | 4 | 8
      device: "cuda" # Device to run the model
    Qwen/Qwen-7B-Chat:
      model_path: "Qwen/Qwen-7B-Chat" # Directory of the model
      quantize: null  # null | 4 | 8
      device: "cuda" # Device to run the model
      precise: null # "bf16" | "fp16"
    augmxnt/shisa-7b-v1:
      model_path: "augmxnt/shisa-7b-v1" # Directory of the model
      device: "cuda" # Device to run the model
    01-ai/Yi-6B-Chat:
      model_path: "01-ai/Yi-6B-Chat" # Directory of the model
      device: "cuda" # Device to run the model

ImgCap:
  id: "Salesforce/blip-image-captioning-large" # The model you want to use
  host: "0.0.0.0" # Host of the API service you want to start
  port: 11003 # Port of the API service you want to start  
  config:
    Salesforce/blip-image-captioning-large:
      model_path: "Salesforce/blip-image-captioning-large" # Directory of the model
      device: "cuda" # Device to run the model

OCR:
  id: "paddlepaddle/PaddleOCR" # The model you want to use
  host: "0.0.0.0" # Host of the API service you want to start
  port: 11004 # Port of the API service you want to start
  config:
    paddlepaddle/PaddleOCR:
      model_path: "paddlepaddle/PaddleOCR" # Directory of the model
      lang: "ch" # Language ["ch", "en", "fr", "german", "korean", "japan"]

TTS:
  id: "AkagawaTsurunaki/GPT-SoVITS" # The model you want to use
  host: "0.0.0.0" # Host of the API service you want to start
  port: 11005 # Port of the API service you want to start
  config:
    AkagawaTsurunaki/GPT-SoVITS:
      # Under developing for quick installing

VLA:
  ShowUI:
    id: "showlab/ShowUI-2B"
    host: "0.0.0.0"
    port: 11009
    config: 
      min_pixels: 200704 # 256*28*28
      max_pixels: 1053696 # 1344*28*28
      showui_model_path: "showlab/ShowUI-2B" # Directory of the model
      showui_model_device: auto # Device to run the model
      qwen_vl_2b_instruct_model_path: "Qwen/Qwen2-VL-2B-Instruct" # Directory of the model